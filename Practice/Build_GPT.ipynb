{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.get_num_threads()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of text: 1115394 characters\n",
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you\n"
     ]
    }
   ],
   "source": [
    "# load text dataset\n",
    "with open(\"input.txt\", 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "print(\"length of text: {} characters\".format(len(text)))\n",
    "print(text[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars:  65\n",
      "\n",
      "   ! $ & ' , - . 3 : ; ? A B C D E F G H I J K L M N O P Q R S T U V W X Y Z a b c d e f g h i j k l m n o p q r s t u v w x y z\n"
     ]
    }
   ],
   "source": [
    "# list all the chars in the text\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(\"total chars: \", vocab_size)\n",
    "print(\" \".join(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded text:  [46, 47, 47, 1, 58, 46, 43, 56, 43, 2]\n",
      "decode text:  hii there!\n"
     ]
    }
   ],
   "source": [
    "# tokenize the text\n",
    "char_to_ix = { ch:i for i,ch in enumerate(chars) }\n",
    "ix_to_char = { i:ch for i,ch in enumerate(chars) }\n",
    "token_encode = lambda s: [char_to_ix[c] for c in s]\n",
    "token_decode = lambda i: \"\".join([ix_to_char[c] for c in i])\n",
    "\n",
    "print(\"encoded text: \", token_encode(\"hii there!\"))\n",
    "print(\"decode text: \", token_decode(token_encode(\"hii there!\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1115394]) torch.int64\n",
      "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
      "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
      "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59])\n"
     ]
    }
   ],
   "source": [
    "# convert text to tensor\n",
    "data = torch.tensor(token_encode(text), dtype=torch.long).to(device)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:100])\n",
    "\n",
    "# split data into train and test\n",
    "n = int(0.9 * len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is tensor([18]), the target is 47\n",
      "when input is tensor([18, 47]), the target is 56\n",
      "when input is tensor([18, 47, 56]), the target is 57\n",
      "when input is tensor([18, 47, 56, 57]), the target is 58\n",
      "when input is tensor([18, 47, 56, 57, 58]), the target is 1\n",
      "when input is tensor([18, 47, 56, 57, 58,  1]), the target is 15\n",
      "when input is tensor([18, 47, 56, 57, 58,  1, 15]), the target is 47\n",
      "when input is tensor([18, 47, 56, 57, 58,  1, 15, 47]), the target is 58\n"
     ]
    }
   ],
   "source": [
    "# example of chunk of dataset\n",
    "block_size = 8\n",
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f\"when input is {context}, the target is {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs: torch.Size([4, 8])\n",
      "tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
      "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
      "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
      "        [25, 17, 27, 10,  0, 21,  1, 54]])\n",
      "targets: torch.Size([4, 8])\n",
      "tensor([[43, 58,  5, 57,  1, 46, 43, 39],\n",
      "        [53, 56,  1, 58, 46, 39, 58,  1],\n",
      "        [58,  1, 58, 46, 39, 58,  1, 46],\n",
      "        [17, 27, 10,  0, 21,  1, 54, 39]])\n",
      "------------------------------\n",
      "when input is tensor([24]), the target is 43\n",
      "when input is tensor([24, 43]), the target is 58\n",
      "when input is tensor([24, 43, 58]), the target is 5\n",
      "when input is tensor([24, 43, 58,  5]), the target is 57\n",
      "when input is tensor([24, 43, 58,  5, 57]), the target is 1\n",
      "when input is tensor([24, 43, 58,  5, 57,  1]), the target is 46\n",
      "when input is tensor([24, 43, 58,  5, 57,  1, 46]), the target is 43\n",
      "when input is tensor([24, 43, 58,  5, 57,  1, 46, 43]), the target is 39\n",
      "==============================\n",
      "when input is tensor([44]), the target is 53\n",
      "when input is tensor([44, 53]), the target is 56\n",
      "when input is tensor([44, 53, 56]), the target is 1\n",
      "when input is tensor([44, 53, 56,  1]), the target is 58\n",
      "when input is tensor([44, 53, 56,  1, 58]), the target is 46\n",
      "when input is tensor([44, 53, 56,  1, 58, 46]), the target is 39\n",
      "when input is tensor([44, 53, 56,  1, 58, 46, 39]), the target is 58\n",
      "when input is tensor([44, 53, 56,  1, 58, 46, 39, 58]), the target is 1\n",
      "==============================\n",
      "when input is tensor([52]), the target is 58\n",
      "when input is tensor([52, 58]), the target is 1\n",
      "when input is tensor([52, 58,  1]), the target is 58\n",
      "when input is tensor([52, 58,  1, 58]), the target is 46\n",
      "when input is tensor([52, 58,  1, 58, 46]), the target is 39\n",
      "when input is tensor([52, 58,  1, 58, 46, 39]), the target is 58\n",
      "when input is tensor([52, 58,  1, 58, 46, 39, 58]), the target is 1\n",
      "when input is tensor([52, 58,  1, 58, 46, 39, 58,  1]), the target is 46\n",
      "==============================\n",
      "when input is tensor([25]), the target is 17\n",
      "when input is tensor([25, 17]), the target is 27\n",
      "when input is tensor([25, 17, 27]), the target is 10\n",
      "when input is tensor([25, 17, 27, 10]), the target is 0\n",
      "when input is tensor([25, 17, 27, 10,  0]), the target is 21\n",
      "when input is tensor([25, 17, 27, 10,  0, 21]), the target is 1\n",
      "when input is tensor([25, 17, 27, 10,  0, 21,  1]), the target is 54\n",
      "when input is tensor([25, 17, 27, 10,  0, 21,  1, 54]), the target is 39\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "# example of how to create a batch of data\n",
    "torch.manual_seed(1337)\n",
    "block_size = 8\n",
    "batch_size = 4\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == \"train\" else val_data\n",
    "    ix = torch.randint(len(data) - block_size, size=(batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x, y\n",
    "\n",
    "xb, yb = get_batch(\"train\")\n",
    "print(f\"inputs: {xb.shape}\")\n",
    "print(xb)\n",
    "print(f\"targets: {yb.shape}\")\n",
    "print(yb)\n",
    "print(\"-\"*30)\n",
    "\n",
    "for b in range(batch_size):\n",
    "    for t in range(block_size):\n",
    "        context = xb[b,:t+1]\n",
    "        target = yb[b,t]\n",
    "        print(f\"when input is {context}, the target is {target}\")\n",
    "    print(\"=\"*30)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Simplest Model: Bigram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8, 65]) tensor(4.8786, grad_fn=<NllLossBackward0>)\n",
      "\n",
      "SKIcLT;AcELMoTbvZv C?nq-QE33:CJqkOKH-q;:la!oiywkHjgChzbQ?u!3bLIgwevmyFJGUGp\n",
      "wnYWmnxKWWev-tDqXErVKLgJ\n"
     ]
    }
   ],
   "source": [
    "# bigram model\n",
    "torch.manual_seed(1337)\n",
    "class BigramModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_tabel = nn.Embedding(vocab_size, vocab_size)\n",
    "    \n",
    "    def forward(self, inputs, targets=None):\n",
    "        # inputs: (batch_size, block_size)\n",
    "        # targets: (batch_size, block_size)\n",
    "        logits = self.token_embedding_tabel(inputs) # (batch_size, block_size, vocab_size) / (B, T, C)\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits_rs = logits.view(B*T, C)\n",
    "            targets_rs = targets.view(B*T)\n",
    "            # loss = F.cross_entropy(logits.transpose(1,2), targets)\n",
    "            loss = F.cross_entropy(logits_rs, targets_rs)\n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, idx, max_new_token):\n",
    "        # idx: (batch_size, block_size) array of indices in the current context\n",
    "        for _ in range(max_new_token):\n",
    "            logits, loss = self(idx) # (batch_size, block_size, vocab_size)\n",
    "            # only focus on the last token\n",
    "            last_logits = logits[:, -1, :]\n",
    "            probs = F.softmax(last_logits, dim=-1) # (batch_size, vocab_size)\n",
    "            idx_next = torch.multinomial(input=probs, num_samples=1) # sampling: (batch_size, 1)\n",
    "            idx = torch.cat([idx, idx_next], dim=1) # (batch_size, block_size+1)\n",
    "        \n",
    "        return idx\n",
    "                    \n",
    "# test bigram model\n",
    "model1 = BigramModel(vocab_size).to(device)\n",
    "logits, loss = model1(xb, yb)\n",
    "print(logits.shape, loss)\n",
    "\n",
    "\n",
    "idx_init = torch.zeros((1,1), dtype=torch.long).to(device)\n",
    "print(token_decode(model1.generate(idx_init, max_new_token=100)[0].tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9999, loss: 2.446\n",
      "\n",
      "hayoince al'-wie ry mUThin meeancourenotyeisomy t VI:\n",
      "COMEEPEPEren p:\n",
      "Kad, thicYCHMI pashad a here, RDY ararroutyer'd,\n",
      "Bearnd me lef;\n",
      "MELI d,\n",
      "QUMe gongry RAlise monguee ces g nchee Iss tast theran, s!\n",
      "FJaboaingednvfonghe; bold o ouleareruk ceee.\n",
      "The prnt Whandea at, avenan\n",
      "OUSino th\n",
      "Mainol.\n",
      "Five OHa\n"
     ]
    }
   ],
   "source": [
    "model1 = BigramModel(vocab_size).to(device)\n",
    "\n",
    "# train above model\n",
    "optimizer = torch.optim.Adam(model1.parameters(), lr=1e-3)\n",
    "batch_size = 32\n",
    "for iter in range(10000):\n",
    "    xb, yb = get_batch(\"train\")\n",
    "    logits, loss = model1(xb, yb)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "print(f\"epoch: {iter}, loss: {loss.item():.3f}\")\n",
    "print(token_decode(model1.generate(idx_init, max_new_token=300)[0].tolist()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Self-Attention \n",
    "Different from the attention used in encoder-decoder structure, the key, query, and value here all come from the same source, i.e., the input sequence. That's why it calls self-attention. The cross attention will have separate source of nodes to pull information from.\n",
    "\n",
    "Notes:\n",
    "- Attention is a **communication mechanism**. Can be seen as nodes in a directed graph looking at each other and aggregating information with a weighted sum from all nodes that point to them, with data-dependent weights.\n",
    "- There is no notion of space. Attention simply acts over a set of vectors. This is why we need to positionally encode tokens.\n",
    "- Each example across batch dimension is of course processed completely independently and never \"talk\" to each other\n",
    "- In an \"encoder\" attention block just delete the single line that does masking with `tril`, allowing all tokens to communicate. This block here is called a \"decoder\" attention block because it has triangular masking, and is usually used in autoregressive settings, like language modeling.\n",
    "- \"self-attention\" just means that the keys and values are produced from the same source as queries. In \"cross-attention\", the queries still get produced from x, but the keys and values come from some other, external source (e.g. an encoder module)\n",
    "- \"Scaled\" attention additional divides `wei` by 1/sqrt(head_size). This makes it so when input Q,K are unit variance, wei will be unit variance too and Softmax will stay diffuse and not saturate too much. Illustration below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1574, 0.8426, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2088, 0.1646, 0.6266, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5792, 0.1187, 0.1889, 0.1131, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0294, 0.1052, 0.0469, 0.0276, 0.7909, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0176, 0.2689, 0.0215, 0.0089, 0.6812, 0.0019, 0.0000, 0.0000],\n",
      "        [0.1691, 0.4066, 0.0438, 0.0416, 0.1048, 0.2012, 0.0329, 0.0000],\n",
      "        [0.0210, 0.0843, 0.0555, 0.2297, 0.0573, 0.0709, 0.2423, 0.2391]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "torch.Size([4, 8, 16])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "B, T, C = 4, 8, 32\n",
    "x = torch.randn(B, T, C)\n",
    "\n",
    "# single head perform self-attention\n",
    "head_size = 16\n",
    "key = nn.Linear(C, head_size, bias=False)\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "value = nn.Linear(C, head_size, bias=False)\n",
    "k = key(x) # (B, T, head_size)\n",
    "q = query(x) # (B, T, head_size)\n",
    "wei = torch.matmul(q, k.transpose(-2,-1)) # (B, T, T), each row of wei[i] is a query vector (weights of each token)\n",
    "\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "wei = wei.masked_fill(tril == 0, float(\"-inf\"))\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "\n",
    "v = value(x) # (B, T, head_size)\n",
    "out = torch.matmul(wei, v) # (B, T, head_size)\n",
    "print(wei[0])\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 0.]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tril"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.3863, -2.0786,  1.1903, -0.4894, -1.4285],\n",
       "        [ 0.0935,  1.1171,  1.5847, -0.0534,  0.6406],\n",
       "        [ 0.8000, -1.9087,  0.7417,  1.1109,  0.0096]], requires_grad=True)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 4, 4])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = torch.randint(5, (3,), dtype=torch.int64)\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.1895, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = F.cross_entropy(input, target)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attention\n",
    "##### Why is it important to have scale step in attention?\n",
    "Without scale (i.e., using sqrt(head_size)), the variance of attention weights will be equal to the head_size. For softmax function, if the weight takes very positive or very negative numbers, the softmax output will actually converge to one-hot vector. But we need the coefficents to be diffuse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1799, 0.1333, 0.2197, 0.1988, 0.2684])\n",
      "tensor([6.1282e-06, 7.5628e-10, 2.4723e-03, 1.2309e-04, 9.9740e-01])\n"
     ]
    }
   ],
   "source": [
    "# example of softmax\n",
    "print(torch.softmax(torch.tensor([0.1, -0.2, 0.3, 0.2, 0.5]), dim=-1))\n",
    "print(torch.softmax(torch.tensor([0.1, -0.2, 0.3, 0.2, 0.5])*30, dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "without normalization:\n",
      "tensor([[-2.6915,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
      "        [-3.3898,  0.3375,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
      "        [-0.9337,  1.7324,  0.3765,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
      "        [ 0.9253,  0.2274,  0.7229,  0.5320,    -inf,    -inf,    -inf,    -inf],\n",
      "        [-0.7654, -2.0773,  0.2287,  1.8543, -1.6185,    -inf,    -inf,    -inf],\n",
      "        [-3.8860,  0.2991, -1.5944, -0.2074, -3.0268, -0.3258,    -inf,    -inf],\n",
      "        [-0.0754,  2.7371,  0.9082,  1.8673, -0.0628,  1.1669,  0.6911,    -inf],\n",
      "        [-1.6482, -0.1062,  1.5168,  2.8792,  0.2492,  0.4291,  0.6414, -1.0879]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "softmax:\n",
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0235, 0.9765, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0524, 0.7534, 0.1942, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3345, 0.1665, 0.2732, 0.2258, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0552, 0.0149, 0.1491, 0.7574, 0.0235, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0065, 0.4274, 0.0643, 0.2576, 0.0154, 0.2288, 0.0000, 0.0000],\n",
      "        [0.0295, 0.4907, 0.0788, 0.2056, 0.0298, 0.1021, 0.0634, 0.0000],\n",
      "        [0.0067, 0.0315, 0.1599, 0.6245, 0.0450, 0.0539, 0.0666, 0.0118]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "=====================================\n",
      "with normalization:\n",
      "tensor([[-0.6729,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
      "        [-0.8475,  0.0844,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
      "        [-0.2334,  0.4331,  0.0941,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
      "        [ 0.2313,  0.0568,  0.1807,  0.1330,    -inf,    -inf,    -inf,    -inf],\n",
      "        [-0.1914, -0.5193,  0.0572,  0.4636, -0.4046,    -inf,    -inf,    -inf],\n",
      "        [-0.9715,  0.0748, -0.3986, -0.0518, -0.7567, -0.0815,    -inf,    -inf],\n",
      "        [-0.0188,  0.6843,  0.2271,  0.4668, -0.0157,  0.2917,  0.1728,    -inf],\n",
      "        [-0.4121, -0.0266,  0.3792,  0.7198,  0.0623,  0.1073,  0.1603, -0.2720]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmax:\n",
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2826, 0.7174, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2307, 0.4492, 0.3201, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2705, 0.2272, 0.2572, 0.2452, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1744, 0.1256, 0.2235, 0.3356, 0.1409, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0847, 0.2412, 0.1502, 0.2125, 0.1050, 0.2063, 0.0000, 0.0000],\n",
      "        [0.1052, 0.2126, 0.1346, 0.1710, 0.1056, 0.1436, 0.1275, 0.0000],\n",
      "        [0.0715, 0.1051, 0.1577, 0.2217, 0.1149, 0.1202, 0.1267, 0.0822]],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "B, T, C = 1, 8, 32\n",
    "x = torch.randn(B, T, C)\n",
    "\n",
    "# single head perform self-attention\n",
    "head_size = 16\n",
    "\n",
    "# transform from int to float\n",
    "key = nn.Linear(C, head_size, bias=False)\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "value = nn.Linear(C, head_size, bias=False)\n",
    "k = key(x) # (B, T, head_size)\n",
    "q = query(x) # (B, T, head_size)\n",
    "wei = torch.matmul(q, k.transpose(-2,-1)) # (B, T, T), each row of wei[i] is a query vector (weights of each token)\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "wei = wei.masked_fill(tril == 0, float(\"-inf\"))\n",
    "print(\"without normalization:\")\n",
    "print(wei[0])\n",
    "print(\"softmax:\")\n",
    "print(F.softmax(wei, dim=-1)[0])\n",
    "\n",
    "print(\"=====================================\")\n",
    "print(\"with normalization:\")\n",
    "print(wei[0]/torch.sqrt(torch.tensor(head_size).long()))\n",
    "print(\"softmax:\")\n",
    "print(F.softmax(wei/torch.sqrt(torch.tensor(head_size).long()), dim=-1)[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Matematical Trick in Self-Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
      "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
      "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "B, T, C = 4, 8, 2\n",
    "x = torch.randn(B, T, C)\n",
    "\n",
    "# version 1: bag of words using for loop\n",
    "xbow_loop = torch.zeros(B, T, C)\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        x_prev = x[b,:t+1,:] # (t, C)\n",
    "        xbow_loop[b,t] = torch.mean(x_prev, dim=0)\n",
    "\n",
    "xbow_mat1 = torch.zeros(B, T, C)\n",
    "\n",
    "# version 2\n",
    "wei = torch.tril(torch.ones(T, T))\n",
    "wei = wei / wei.sum(dim=1, keepdim=True)\n",
    "for b in range(B):\n",
    "    xbow_mat1[b] = torch.matmul(wei, x[b])\n",
    "print(torch.allclose(xbow_loop, xbow_mat1, atol=1e-7))\n",
    "\n",
    "# version 3\n",
    "xbow_mat2 = torch.matmul(wei, x)\n",
    "# xbow_mat2 = wei @ x # (T, T) @ (B, T, C) = (B, T, C)\n",
    "print(torch.allclose(xbow_loop, xbow_mat2, atol=1e-7))\n",
    "print(wei)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$sofxmax(\\mathbf{z})_i=\\frac{e^{z_i}}{\\sum_{j=1}^K e^{z_j}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
      "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
      "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# version 4: use softmax\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "wei = torch.zeros(T, T)\n",
    "wei = wei.masked_fill(tril==0, float(\"-inf\"))\n",
    "print(wei)\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "print(wei)\n",
    "xbow_mat3 = torch.matmul(wei, x)\n",
    "print(torch.allclose(xbow_loop, xbow_mat3, atol=1e-7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=\n",
      "tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "b=\n",
      "tensor([[2., 7.],\n",
      "        [6., 4.],\n",
      "        [6., 5.]])\n",
      "c1=\n",
      "tensor([[2.0000, 7.0000],\n",
      "        [4.0000, 5.5000],\n",
      "        [4.6667, 5.3333]])\n",
      "c2=\n",
      "tensor([[2.0000, 7.0000],\n",
      "        [4.0000, 5.5000],\n",
      "        [4.6667, 5.3333]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "a = torch.tril(torch.ones(3,3))\n",
    "a = a / torch.sum(a, dim=1, keepdim=True) # average\n",
    "b = torch.randint(0,10,(3,2)).float()\n",
    "c1 = a @ b\n",
    "c2 = torch.matmul(a, b)\n",
    "print(\"a=\")\n",
    "print(a)\n",
    "print(\"b=\")\n",
    "print(b)\n",
    "print(\"c1=\")\n",
    "print(c1)\n",
    "print(\"c2=\")\n",
    "print(c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 5])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 10\n",
    "embedding_dim = 5\n",
    "a = torch.arange(block_size)\n",
    "print(a.shape)\n",
    "emb = nn.Embedding(block_size, embedding_dim)\n",
    "emb(a).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch,gather function\n",
    "input = torch.randint(0, 10, size=(3,4)).long()\n",
    "index = torch.randint(0, 3, size=(2,4)).long()\n",
    "gather_dim0 = torch.gather(input, dim=0, index=index)\n",
    "gather_dim1 = torch.gather(input, dim=1, index=index)\n",
    "print(f\"input:\\n {input}\")\n",
    "print(f\"index\\n: {index}\")\n",
    "print(f\"gather (dim=0):\\n {gather_dim0}\")\n",
    "print(f\"gather (dim=1):\\n {gather_dim1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross entropy loss\n",
    "def compute_cross_entropy(input, target):\n",
    "    # input: (batch_size, block_size, vocab_size): vocab_size is the number of classes, i.e., it contains the probability of each class\n",
    "    # target: (batch_size, block_size)\n",
    "    # return: (batch_size, block_size)\n",
    "    input = torch.softmax(input, dim=2)\n",
    "    p = torch.gather(input, dim=2, index=target.unsqueeze(2)).squeeze(2) # batch_size, block_size\n",
    "    loss = torch.mean(-torch.log(p))\n",
    "    return loss\n",
    "\n",
    "torch.manual_seed(0)\n",
    "word_to_idx = {\"cat\": 0, \"dog\": 1, \"bird\": 2, \"fish\": 3}\n",
    "vs = len(word_to_idx)\n",
    "bs = 2 # batch size\n",
    "ts = 3 # block size\n",
    "embedding_dim = 4\n",
    "embedding = nn.Embedding(vs, embedding_dim)\n",
    "print(f\"embedding wight:\\n {embedding.weight}\")\n",
    "\n",
    "input_index = torch.randint(0, vs, size=(bs,ts)).long()\n",
    "target_index = torch.randint(0, vs, size=(bs,ts)).long()\n",
    "\n",
    "print(f\"input index:\\n {input_index}\")\n",
    "print(f\"target index:\\n {target_index}\")\n",
    "\n",
    "embed_out = embedding(input_index)\n",
    "print(f\"embed out:\\n {embed_out.shape}\") # batch_size, block_size, embedding_dim\n",
    "print(embed_out)\n",
    "\n",
    "loss1 = F.cross_entropy(embed_out.transpose(1,2), target_index)\n",
    "loss2 = compute_cross_entropy(embed_out, target_index)\n",
    "print(f\"loss1: {loss1}, loss2: {loss2}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# torch.multinomial\n",
    "weights = torch.tensor([0.1, 0.2, 0.3, 0.4])\n",
    "sampled_index = torch.multinomial(weights, 1)\n",
    "\n",
    "# The result is a tensor containing the index of the randomly chosen item\n",
    "# For example, if the result is 2, it means that the item \"orange\" was chosen\n",
    "print(sampled_index.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch normalization\n",
    "class BatchNorm1d:\n",
    "    \n",
    "    def __init__(self, dim, eps=1e-5, momentum=0.1, training=True):\n",
    "        self.eps = eps\n",
    "        self.momentum = momentum\n",
    "        self.training = training\n",
    "        self.gamma = torch.ones(dim) # layer norm gain\n",
    "        self.beta = torch.zeros(dim) # layer norm bias\n",
    "        self.running_mean = torch.zeros(dim)\n",
    "        self.running_var = torch.ones(dim)\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        # x: (batch_size, block_size, embed_size)\n",
    "        if self.training:\n",
    "            xmean = x.mean(dim=-1, keepdim=True) # batch mean\n",
    "            xvar = x.var(dim=-1, keepdim=True) # batch variance\n",
    "        else:\n",
    "            xmean = self.running_mean\n",
    "            xvar = self.running_var\n",
    "        \n",
    "        xhat = (x - xmean) / torch.sqrt(xvar + self.eps) # normalize\n",
    "        self.out = self.gamma * xhat + self.beta # scale and shift\n",
    "        \n",
    "        # update running mean and variance\n",
    "        if self.training:\n",
    "            with torch.no_grad():\n",
    "                self.running_mean = (1 - self.momentum) * self.running_mean + self.momentum * xmean\n",
    "                self.running_var = (1 - self.momentum) * self.running_var + self.momentum * xvar\n",
    "        return self.out\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [self.gamma, self.beta]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 100])\n",
      "tensor(0.2217)\n",
      "tensor(1.4339)\n",
      "-------\n",
      "tensor(8.9407e-09)\n",
      "tensor(1.0000)\n"
     ]
    }
   ],
   "source": [
    "dim = 100\n",
    "bs = 32\n",
    "module = BatchNorm1d(dim=dim)\n",
    "x = torch.randn(bs, dim)\n",
    "x = module(x)\n",
    "print(x.shape)\n",
    "print(x[:,0].mean())\n",
    "print(x[:,0].var())\n",
    "print(\"-------\")\n",
    "print(x[0,:].mean())\n",
    "print(x[0,:].var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_batches in train: 3922\n",
      "num_batches in val: 436\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.distributed as dist\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "import torch.multiprocessing as mp\n",
    "\n",
    "\n",
    "# load text dataset\n",
    "with open(\"input.txt\", 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "# list all the chars in the text\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "# create a mapping from char to index\n",
    "stoi = {c: i for i, c in enumerate(chars)}\n",
    "itos = {i: c for i, c in enumerate(chars)}\n",
    "token_encoder = lambda s: [stoi[c] for c in s]\n",
    "token_decoder = lambda l: ''.join([itos[i] for i in l])\n",
    "\n",
    "# creat dataset for train and val data\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, data, block_size):\n",
    "        # self.data = torch.tensor(data)\n",
    "        self.data = data\n",
    "        self.block_size = block_size\n",
    "        self.num_blocks = len(self.data) // self.block_size\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.num_blocks\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index * self.block_size: (index + 1) * self.block_size]\n",
    "        y = self.data[index * self.block_size + 1: (index + 1) * self.block_size + 1]\n",
    "        return x, y\n",
    "    \n",
    "\n",
    "\n",
    "model_paras = {'embedding_size': 384,\n",
    "               'head_size': 64,\n",
    "               'vocab_size': vocab_size,\n",
    "               'block_size': 8,\n",
    "               'num_heads': 6,\n",
    "               'num_layers': 6,\n",
    "               'dropout': 0.2,\n",
    "               'lr': 3e-4,\n",
    "               'batch_size': 32,\n",
    "               'num_epochs': 10}\n",
    "\n",
    "\n",
    "data = token_encoder(text)\n",
    "# convert to tensor\n",
    "data = torch.tensor(data, dtype=torch.long)\n",
    "train_data = data[:int(len(data)*0.9)]\n",
    "train_set = TextDataset(train_data, model_paras['block_size'])\n",
    "val_data = data[int(len(data)*0.9):]\n",
    "val_set = TextDataset(val_data, model_paras['block_size'])\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=model_paras['batch_size'], shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=model_paras['batch_size'], shuffle=False)\n",
    "num_batches = len(train_loader)\n",
    "print(f\"num_batches in train: {num_batches}\")\n",
    "print(f\"num_batches in val: {len(val_loader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp.cpu_count()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To modify the main_worker function to include validation after each epoch and return the final trained model, you'll need to make a few changes. First, you'll need to pass a validation dataset and DataLoader to the main_worker function. You'll also need to use a Queue from the multiprocessing module to return the trained model from each process. Here's a modified version of the main_worker function:\n",
    "\n",
    "```\n",
    "import torch.multiprocessing as mp\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "import torch.distributed as dist\n",
    "import torch.utils.data\n",
    "from torch.utils.data import DataLoader, DistributedSampler\n",
    "\n",
    "def main_worker(rank, world_size, model, train_dataset, val_dataset, batch_size, epochs, queue):\n",
    "    # Setup\n",
    "    os.environ['MASTER_ADDR'] = 'localhost'\n",
    "    os.environ['MASTER_PORT'] = '12355'\n",
    "    dist.init_process_group(\"gloo\", rank=rank, world_size=world_size)\n",
    "\n",
    "    # Create train sampler and DataLoader\n",
    "    train_sampler = DistributedSampler(train_dataset, num_replicas=world_size, rank=rank)\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler, num_workers=4)\n",
    "\n",
    "    # Create validation DataLoader\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "    # Move the model to the current device and wrap with DDP\n",
    "    device = torch.device(f\"cpu:{rank}\")\n",
    "    model.to(device)\n",
    "    ddp_model = DDP(model, device_ids=[device], output_device=device)\n",
    "\n",
    "    # Training and validation loop\n",
    "    for epoch in range(epochs):\n",
    "        # Training\n",
    "        ddp_model.train()\n",
    "        train_sampler.set_epoch(epoch)\n",
    "        for batch_idx, batch in enumerate(train_dataloader):\n",
    "            # ... (training code)\n",
    "\n",
    "        # Validation\n",
    "        ddp_model.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, batch in enumerate(val_dataloader):\n",
    "                # ... (validation code)\n",
    "        \n",
    "    # Save the trained model in the queue\n",
    "    queue.put(model.state_dict())\n",
    "\n",
    "# Initialize the model, datasets, and multiprocessing queue\n",
    "model = ... # Your model definition\n",
    "train_dataset = ... # Your train dataset definition\n",
    "val_dataset = ... # Your validation dataset definition\n",
    "queue = mp.Queue()\n",
    "\n",
    "# Create and start the processes\n",
    "processes = []\n",
    "world_size = 8\n",
    "for rank in range(world_size):\n",
    "    p = mp.Process(target=main_worker, args=(rank, world_size, model, train_dataset, val_dataset, batch_size, epochs, queue))\n",
    "    p.start()\n",
    "    processes.append(p)\n",
    "\n",
    "# Collect the trained models from each process\n",
    "trained_models = []\n",
    "for _ in range(world_size):\n",
    "    trained_models.append(queue.get())\n",
    "\n",
    "# Join the processes\n",
    "for p in processes:\n",
    "    p.join()\n",
    "\n",
    "# Do something with the trained models, e.g., average their parameters or select the best one based on validation performance\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "In this modified main_worker function, we pass the validation dataset, create a validation DataLoader, and add a validation loop after the training loop in each epoch. To return the final trained model, we use a multiprocessing Queue to collect the models' state dictionaries from each process.\n",
    "\n",
    "Once you have the trained models, you can decide what to do with them, such as averaging their parameters or selecting the best model based on validation performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
